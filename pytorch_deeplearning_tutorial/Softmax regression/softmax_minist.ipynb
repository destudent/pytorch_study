{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>05. 소프트맥스 회귀로 MNIST 데이터 분류하기</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.토치비전 소개하기</h4>\n",
    "\n",
    "본격적인 실습에 들어가기에 앞서 토치비전(torchvision)이라는 도구를 설명하겠습니다. torchvision은 유명한 데이터셋들, 이미 구현되어져 있는 유명한 모델들, 일반적인 이미지 전처리 도구들을 포함하고 있는 패키지입니다. 아래의 링크는 torchvision에 어떤 데이터셋들(datasets)과 모델들(models) 그리고 어떤 전처리 방법들(transforms)을 제공하고 있는지 보여줍니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. 분류기 구현을 위한 사전 설정</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4. Minist 분류기 구현하기</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:00, 19245403.32it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 33214413.76it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1649664it [00:00, 10540383.08it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 24237964.42it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1643987637853/work/torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 인자 root는 MNIST 데이터를 다운로드 받을 경로입니다. 두번째 인자 train은 인자로 True를 주면, MNIST의 훈련 데이터를 리턴받으며 False를 주면 테스트 데이터를 리턴받습니다. 세번째 인자 transform은 현재 데이터를 파이토치 텐서로 변환해줍니다. 네번째 인자 download는 해당 경로에 MNIST 데이터가 없다면 다운로드 받겠다는 의미입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size, # 배치 크기는 100\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 DataLoader에는 4개의 인자가 있습니다. 첫번째 인자인 dataset은 로드할 대상을 의미하며, 두번째 인자인 batch_size는 배치 크기, shuffle은 매 에포크마다 미니 배치를 셔플할 것인지의 여부, drop_last는 마지막 배치를 버릴 것인지를 의미합니다.\n",
    "\n",
    "- drop_last를 하는 이유를 이해하기 위해서 1,000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 해봅시다. 1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남습니다. 이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있습니다. 이때 마지막 배치를 버리려면 drop_last=True를 해주면 됩니다. 이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(784,10 , bias=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to() 함수는 연산을 어디서 수행할지를 정합니다. to() 함수는 모델의 매개변수를 지정한 장치의 메모리로 보냅니다. CPU를 사용할 경우에는 필요가 없지만, GPU를 사용하려면 to('cuda')를 해 줄 필요가 있습니다. 아무것도 지정하지 않은 경우에는 CPU 연산이라고 보면 됩니다.\n",
    "\n",
    "bias는 편향 b를 사용할 것인지를 나타냅니다. 기본값은 True이므로 굳이 할 필요는 없지만 명시적으로 True를 해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비용함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss().to(device)#내부적으로 소프트맥스 함수를 포함함\n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞서 소프트맥스 회귀를 배울 때는 torch.nn.functional.cross_entropy()를 사용하였으나 여기서는 torch.nn.CrossEntropyLoss()을 사용하고 있습니다. 둘 다 파이토치에서 제공하는 크로스 엔트로피 함수로 둘 다 소프트맥스 함수를 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.535150588\n",
      "Epoch: 0002 cost = 0.359577715\n",
      "Epoch: 0003 cost = 0.331264287\n",
      "Epoch: 0004 cost = 0.316404670\n",
      "Epoch: 0005 cost = 0.307107031\n",
      "Epoch: 0006 cost = 0.300456554\n",
      "Epoch: 0007 cost = 0.294933408\n",
      "Epoch: 0008 cost = 0.290956169\n",
      "Epoch: 0009 cost = 0.287074089\n",
      "Epoch: 0010 cost = 0.284515589\n",
      "Epoch: 0011 cost = 0.281914055\n",
      "Epoch: 0012 cost = 0.279526860\n",
      "Epoch: 0013 cost = 0.277636588\n",
      "Epoch: 0014 cost = 0.275874764\n",
      "Epoch: 0015 cost = 0.274422735\n",
      "learning 끝\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X,Y in data_loader:\n",
    "        #배치 크기가 100이므로 아래의 연산에서 X는 (100,784)의 텐서가 된다\n",
    "        X = X.view(-1,28*28).to(device) #784의 텐서로 변경\n",
    "        #레이블은 원-핫 인코딩이 된 상태가 아니라 0~ 9 의 정수\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis,Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost+= cost/total_batch\n",
    "\n",
    "    \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "print('learning 끝')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8883000016212463\n",
      "Label:  7\n",
      "Prediction:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#테스트 데이터를 사용해 모델 테스트\n",
    "with torch.no_grad(): # torch.no_grad()를 사용하면 gradient계산을 수행하지 않는다.\n",
    "    X_test = mnist_test.test_data.view(-1,28*28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction=linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction,1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
