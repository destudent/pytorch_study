{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>07. 커스텀 데이터셋</h3>\n",
    "파이토치에서는 데이터셋을 좀 더 쉽게 다룰 수 있도록 유용한 도구로서 torch.utils.data.Dataset과 torch.utils.data.DataLoader를 제공합니다. 이를 사용하면 미니 배치 학습, 데이터 셔플(shuffle), 병렬 처리까지 간단히 수행할 수 있습니다. 기본적인 사용 방법은 Dataset을 정의하고, 이를 DataLoader에 전달하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. 커스텀 데이터셋</h4>\n",
    "torch.utils.data.Dataset을 상속받아 직접 커스텀 데이터셋(Custom Dataset)을 만드는 경우도 있습니다. torch.utils.data.Dataset은 파이토치에서 데이터셋을 제공하는 추상 클래스입니다. Dataset을 상속받아 다음 메소드들을 오버라이드 하여 커스텀 데이터셋을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    #데이터셋의 전처리를 해주는 부분\n",
    "    def __init__(self):\n",
    "    \n",
    "    #데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "    def __len__(self):\n",
    "\n",
    "    #데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "# len(dataset)을 했을 때 데이터셋의 크기를 리턴할 len\n",
    "# dataset[i]을 했을 때 i번째 샘플을 가져오도록 하는 인덱싱을 위한 get_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. 커스텀 데이터셋으로 선형회귀 구현하기</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                   [93, 88, 93],\n",
    "                   [89, 91, 90],\n",
    "                   [96, 98, 100],\n",
    "                   [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "    \n",
    "    #총 데이터의 개수를 리턴\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    #인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "    def __getitem__(self,idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 24405.167969\n",
      "Epoch    0/20 Batch 2/3 Cost: 4069.362793\n",
      "Epoch    0/20 Batch 3/3 Cost: 3413.354492\n",
      "Epoch    1/20 Batch 1/3 Cost: 585.284668\n",
      "Epoch    1/20 Batch 2/3 Cost: 76.582520\n",
      "Epoch    1/20 Batch 3/3 Cost: 30.106997\n",
      "Epoch    2/20 Batch 1/3 Cost: 11.282576\n",
      "Epoch    2/20 Batch 2/3 Cost: 7.612187\n",
      "Epoch    2/20 Batch 3/3 Cost: 4.536011\n",
      "Epoch    3/20 Batch 1/3 Cost: 0.670541\n",
      "Epoch    3/20 Batch 2/3 Cost: 0.078032\n",
      "Epoch    3/20 Batch 3/3 Cost: 0.066412\n",
      "Epoch    4/20 Batch 1/3 Cost: 0.006642\n",
      "Epoch    4/20 Batch 2/3 Cost: 0.401432\n",
      "Epoch    4/20 Batch 3/3 Cost: 0.683115\n",
      "Epoch    5/20 Batch 1/3 Cost: 0.014797\n",
      "Epoch    5/20 Batch 2/3 Cost: 0.553628\n",
      "Epoch    5/20 Batch 3/3 Cost: 0.564562\n",
      "Epoch    6/20 Batch 1/3 Cost: 0.090351\n",
      "Epoch    6/20 Batch 2/3 Cost: 0.041583\n",
      "Epoch    6/20 Batch 3/3 Cost: 1.198326\n",
      "Epoch    7/20 Batch 1/3 Cost: 0.249440\n",
      "Epoch    7/20 Batch 2/3 Cost: 0.527470\n",
      "Epoch    7/20 Batch 3/3 Cost: 0.016601\n",
      "Epoch    8/20 Batch 1/3 Cost: 0.397581\n",
      "Epoch    8/20 Batch 2/3 Cost: 0.079175\n",
      "Epoch    8/20 Batch 3/3 Cost: 0.504803\n",
      "Epoch    9/20 Batch 1/3 Cost: 0.086787\n",
      "Epoch    9/20 Batch 2/3 Cost: 0.731050\n",
      "Epoch    9/20 Batch 3/3 Cost: 0.015541\n",
      "Epoch   10/20 Batch 1/3 Cost: 0.003909\n",
      "Epoch   10/20 Batch 2/3 Cost: 0.596695\n",
      "Epoch   10/20 Batch 3/3 Cost: 0.015920\n",
      "Epoch   11/20 Batch 1/3 Cost: 0.413094\n",
      "Epoch   11/20 Batch 2/3 Cost: 0.371098\n",
      "Epoch   11/20 Batch 3/3 Cost: 0.003914\n",
      "Epoch   12/20 Batch 1/3 Cost: 0.451212\n",
      "Epoch   12/20 Batch 2/3 Cost: 0.061974\n",
      "Epoch   12/20 Batch 3/3 Cost: 0.476398\n",
      "Epoch   13/20 Batch 1/3 Cost: 0.084027\n",
      "Epoch   13/20 Batch 2/3 Cost: 0.761012\n",
      "Epoch   13/20 Batch 3/3 Cost: 0.016862\n",
      "Epoch   14/20 Batch 1/3 Cost: 0.006838\n",
      "Epoch   14/20 Batch 2/3 Cost: 0.427498\n",
      "Epoch   14/20 Batch 3/3 Cost: 0.671511\n",
      "Epoch   15/20 Batch 1/3 Cost: 0.096215\n",
      "Epoch   15/20 Batch 2/3 Cost: 0.030523\n",
      "Epoch   15/20 Batch 3/3 Cost: 1.192520\n",
      "Epoch   16/20 Batch 1/3 Cost: 0.132983\n",
      "Epoch   16/20 Batch 2/3 Cost: 0.573723\n",
      "Epoch   16/20 Batch 3/3 Cost: 0.039871\n",
      "Epoch   17/20 Batch 1/3 Cost: 0.012475\n",
      "Epoch   17/20 Batch 2/3 Cost: 0.387485\n",
      "Epoch   17/20 Batch 3/3 Cost: 0.694767\n",
      "Epoch   18/20 Batch 1/3 Cost: 0.015074\n",
      "Epoch   18/20 Batch 2/3 Cost: 0.552635\n",
      "Epoch   18/20 Batch 3/3 Cost: 0.558388\n",
      "Epoch   19/20 Batch 1/3 Cost: 0.024248\n",
      "Epoch   19/20 Batch 2/3 Cost: 0.108099\n",
      "Epoch   19/20 Batch 3/3 Cost: 1.311419\n",
      "Epoch   20/20 Batch 1/3 Cost: 0.114478\n",
      "Epoch   20/20 Batch 2/3 Cost: 0.572031\n",
      "Epoch   20/20 Batch 3/3 Cost: 0.037111\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, sampels in enumerate(dataloader):\n",
    "\n",
    "        x_train,y_train = sampels\n",
    "\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        cost = F.mse_loss(prediction,y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "        cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.9358]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
